{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing, utils, activations, optimizers\n",
    "from tensorflow.keras import Input, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('../data_en_es/en_es_train_data.pkl')\n",
    "test_data = pd.read_pickle('../data_en_es/en_es_test_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['label'] = train_data['label'].astype(int).astype(str)\n",
    "test_data['label'] = train_data['label'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['user', 'format', 'token', 'part_of_speech', 'label']\n",
    "features = ['user', 'format', 'token', 'part_of_speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_listings = pd.Series({feature : train_data[feature].tolist() for feature in variables})\n",
    "test_listings = pd.Series({feature : train_data[feature].tolist() for feature in variables})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "user              [XEinXf5+, XEinXf5+, XEinXf5+, XEinXf5+, XEinX...\n",
       "format            [reverse_translate, reverse_translate, reverse...\n",
       "token             [i, am, a, boy, i, am, from, mexico, my, name,...\n",
       "part_of_speech    [PRON, VERB, DET, NOUN, PRON, VERB, ADP, PROPN...\n",
       "label             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train_listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_listified = train_data.groupby('user')[variables].apply(lambda data: pd.Series({feature : data[feature].tolist() for feature in variables}))\n",
    "test_data_listified = test_data.groupby('user')[variables].apply(lambda data: pd.Series({feature : data[feature].tolist() for feature in variables}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                       user  \\\n",
       "user                                                          \n",
       "++j955YG  [++j955YG, ++j955YG, ++j955YG, ++j955YG, ++j95...   \n",
       "+/iDvu/I  [+/iDvu/I, +/iDvu/I, +/iDvu/I, +/iDvu/I, +/iDv...   \n",
       "+0UEF02n  [+0UEF02n, +0UEF02n, +0UEF02n, +0UEF02n, +0UEF...   \n",
       "+197nchq  [+197nchq, +197nchq, +197nchq, +197nchq, +197n...   \n",
       "+7lbKZrn  [+7lbKZrn, +7lbKZrn, +7lbKZrn, +7lbKZrn, +7lbK...   \n",
       "...                                                     ...   \n",
       "zv3rQx2W  [zv3rQx2W, zv3rQx2W, zv3rQx2W, zv3rQx2W, zv3rQ...   \n",
       "zx+JF92P  [zx+JF92P, zx+JF92P, zx+JF92P, zx+JF92P, zx+JF...   \n",
       "zyRFO2/B  [zyRFO2/B, zyRFO2/B, zyRFO2/B, zyRFO2/B, zyRFO...   \n",
       "zzZcZM/K  [zzZcZM/K, zzZcZM/K, zzZcZM/K, zzZcZM/K, zzZcZ...   \n",
       "zzjm1vvv  [zzjm1vvv, zzjm1vvv, zzjm1vvv, zzjm1vvv, zzjm1...   \n",
       "\n",
       "                                                     format  \\\n",
       "user                                                          \n",
       "++j955YG  [reverse_translate, reverse_translate, reverse...   \n",
       "+/iDvu/I  [listen, reverse_tap, listen, listen, reverse_...   \n",
       "+0UEF02n  [reverse_tap, listen, reverse_tap, reverse_tap...   \n",
       "+197nchq  [reverse_tap, listen, listen, listen, reverse_...   \n",
       "+7lbKZrn  [reverse_translate, listen, listen, listen, re...   \n",
       "...                                                     ...   \n",
       "zv3rQx2W  [listen, listen, listen, listen, listen, liste...   \n",
       "zx+JF92P  [reverse_translate, listen, listen, listen, li...   \n",
       "zyRFO2/B  [listen, listen, listen, listen, listen, liste...   \n",
       "zzZcZM/K  [reverse_tap, listen, reverse_tap, reverse_tap...   \n",
       "zzjm1vvv  [listen, reverse_tap, reverse_translate, rever...   \n",
       "\n",
       "                                                      token  \\\n",
       "user                                                          \n",
       "++j955YG  [am, i, a, boy, i, am, from, mexico, you, are,...   \n",
       "+/iDvu/I  [what, what, good, morning, good, night, hello...   \n",
       "+0UEF02n  [what, what, hello, and, good, morning, good, ...   \n",
       "+197nchq  [what, what, good, morning, good, evening, hel...   \n",
       "+7lbKZrn  [what, what, good, morning, good, night, good,...   \n",
       "...                                                     ...   \n",
       "zv3rQx2W  [i, speak, english, i, am, sorry, where, i, am...   \n",
       "zx+JF92P  [what, what, i, am, very, good, please, i, am,...   \n",
       "zyRFO2/B  [i, am, from, mexico, are, you, from, mexico, ...   \n",
       "zzZcZM/K  [what, what, a, man, good, morning, good, even...   \n",
       "zzjm1vvv  [what, what, good, night, hello, and, good, mo...   \n",
       "\n",
       "                                             part_of_speech  \\\n",
       "user                                                          \n",
       "++j955YG  [ADP, PRON, DET, NOUN, PRON, VERB, ADP, PROPN,...   \n",
       "+/iDvu/I  [PRON, PRON, ADJ, NOUN, ADJ, NOUN, INTJ, CONJ,...   \n",
       "+0UEF02n  [PRON, PRON, INTJ, CONJ, ADJ, NOUN, ADJ, NOUN,...   \n",
       "+197nchq  [PRON, PRON, ADJ, NOUN, ADJ, NOUN, INTJ, CONJ,...   \n",
       "+7lbKZrn  [PRON, PRON, ADJ, NOUN, ADJ, NOUN, ADJ, NOUN, ...   \n",
       "...                                                     ...   \n",
       "zv3rQx2W  [PRON, VERB, PROPN, PRON, VERB, ADJ, ADV, PRON...   \n",
       "zx+JF92P  [PRON, PRON, PRON, VERB, ADV, ADJ, INTJ, PRON,...   \n",
       "zyRFO2/B  [PRON, VERB, ADP, PROPN, VERB, PRON, ADP, PROP...   \n",
       "zzZcZM/K  [PRON, PRON, DET, NOUN, ADJ, NOUN, ADJ, NOUN, ...   \n",
       "zzjm1vvv  [PRON, PRON, ADJ, NOUN, INTJ, CONJ, ADJ, NOUN,...   \n",
       "\n",
       "                                                      label  \n",
       "user                                                         \n",
       "++j955YG  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "+/iDvu/I  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "+0UEF02n  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "+197nchq  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "+7lbKZrn  [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, ...  \n",
       "...                                                     ...  \n",
       "zv3rQx2W  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "zx+JF92P  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "zyRFO2/B  [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, ...  \n",
       "zzZcZM/K  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "zzjm1vvv  [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[2593 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>format</th>\n      <th>token</th>\n      <th>part_of_speech</th>\n      <th>label</th>\n    </tr>\n    <tr>\n      <th>user</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>++j955YG</th>\n      <td>[++j955YG, ++j955YG, ++j955YG, ++j955YG, ++j95...</td>\n      <td>[reverse_translate, reverse_translate, reverse...</td>\n      <td>[am, i, a, boy, i, am, from, mexico, you, are,...</td>\n      <td>[ADP, PRON, DET, NOUN, PRON, VERB, ADP, PROPN,...</td>\n      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n    </tr>\n    <tr>\n      <th>+/iDvu/I</th>\n      <td>[+/iDvu/I, +/iDvu/I, +/iDvu/I, +/iDvu/I, +/iDv...</td>\n      <td>[listen, reverse_tap, listen, listen, reverse_...</td>\n      <td>[what, what, good, morning, good, night, hello...</td>\n      <td>[PRON, PRON, ADJ, NOUN, ADJ, NOUN, INTJ, CONJ,...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>+0UEF02n</th>\n      <td>[+0UEF02n, +0UEF02n, +0UEF02n, +0UEF02n, +0UEF...</td>\n      <td>[reverse_tap, listen, reverse_tap, reverse_tap...</td>\n      <td>[what, what, hello, and, good, morning, good, ...</td>\n      <td>[PRON, PRON, INTJ, CONJ, ADJ, NOUN, ADJ, NOUN,...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>+197nchq</th>\n      <td>[+197nchq, +197nchq, +197nchq, +197nchq, +197n...</td>\n      <td>[reverse_tap, listen, listen, listen, reverse_...</td>\n      <td>[what, what, good, morning, good, evening, hel...</td>\n      <td>[PRON, PRON, ADJ, NOUN, ADJ, NOUN, INTJ, CONJ,...</td>\n      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>+7lbKZrn</th>\n      <td>[+7lbKZrn, +7lbKZrn, +7lbKZrn, +7lbKZrn, +7lbK...</td>\n      <td>[reverse_translate, listen, listen, listen, re...</td>\n      <td>[what, what, good, morning, good, night, good,...</td>\n      <td>[PRON, PRON, ADJ, NOUN, ADJ, NOUN, ADJ, NOUN, ...</td>\n      <td>[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>zv3rQx2W</th>\n      <td>[zv3rQx2W, zv3rQx2W, zv3rQx2W, zv3rQx2W, zv3rQ...</td>\n      <td>[listen, listen, listen, listen, listen, liste...</td>\n      <td>[i, speak, english, i, am, sorry, where, i, am...</td>\n      <td>[PRON, VERB, PROPN, PRON, VERB, ADJ, ADV, PRON...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>zx+JF92P</th>\n      <td>[zx+JF92P, zx+JF92P, zx+JF92P, zx+JF92P, zx+JF...</td>\n      <td>[reverse_translate, listen, listen, listen, li...</td>\n      <td>[what, what, i, am, very, good, please, i, am,...</td>\n      <td>[PRON, PRON, PRON, VERB, ADV, ADJ, INTJ, PRON,...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>zyRFO2/B</th>\n      <td>[zyRFO2/B, zyRFO2/B, zyRFO2/B, zyRFO2/B, zyRFO...</td>\n      <td>[listen, listen, listen, listen, listen, liste...</td>\n      <td>[i, am, from, mexico, are, you, from, mexico, ...</td>\n      <td>[PRON, VERB, ADP, PROPN, VERB, PRON, ADP, PROP...</td>\n      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>zzZcZM/K</th>\n      <td>[zzZcZM/K, zzZcZM/K, zzZcZM/K, zzZcZM/K, zzZcZ...</td>\n      <td>[reverse_tap, listen, reverse_tap, reverse_tap...</td>\n      <td>[what, what, a, man, good, morning, good, even...</td>\n      <td>[PRON, PRON, DET, NOUN, ADJ, NOUN, ADJ, NOUN, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>zzjm1vvv</th>\n      <td>[zzjm1vvv, zzjm1vvv, zzjm1vvv, zzjm1vvv, zzjm1...</td>\n      <td>[listen, reverse_tap, reverse_translate, rever...</td>\n      <td>[what, what, good, night, hello, and, good, mo...</td>\n      <td>[PRON, PRON, ADJ, NOUN, INTJ, CONJ, ADJ, NOUN,...</td>\n      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2593 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "train_data_listified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index to string mappings for the features, include an index mapping for padding\n",
    "# so padding will have index of 0\n",
    "def feature_mapping(data, pad = \"_PAD_\"):\n",
    "    feature_map = {}\n",
    "    for var in variables:\n",
    "        feature_map[var] = {}\n",
    "\n",
    "        unique_features = list(set(data[var]))\n",
    "        unique_features.insert(0, pad)\n",
    "\n",
    "        tokens_to_index = {feature: index for index, feature in enumerate(unique_features)}\n",
    "        feature_map[var] = tokens_to_index\n",
    "\n",
    "    return feature_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map_train = feature_mapping(train_data)\n",
    "feature_map_test = feature_mapping(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'user': 2594, 'format': 4, 'token': 1968, 'part_of_speech': 17, 'label': 3}\n{'user': 2594, 'format': 4, 'token': 1880, 'part_of_speech': 17, 'label': 3}\n"
     ]
    }
   ],
   "source": [
    "# Vocab sizes\n",
    "print({var: len(feature_map_train[var]) for var in feature_map_train})\n",
    "print({var: len(feature_map_test[var]) for var in feature_map_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8894, 1057)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "max_length_train = train_data['user'].value_counts().max()\n",
    "max_length_test = test_data['user'].value_counts().max()\n",
    "max_length_train, max_length_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll just pad to the length of the longest individual sequence (apparently thats 8894)\n",
    "def add_padding(sequences, feature_map, maxlen = None):\n",
    "    index = [[feature_map[feature] for feature in sequence] for sequence in sequences]\n",
    "    index = preprocessing.sequence.pad_sequences(index, maxlen, value = feature_map[\"_PAD_\"])\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexed_train_data = {var: add_padding(train_data_listified[var], feature_map_train[var], 2048) for var in feature_map_train}\n",
    "Y_train = indexed_train_data.pop('label')\n",
    "\n",
    "indexed_test_data = {var: add_padding(test_data_listified[var], feature_map_test[var], 1024) for var in feature_map_test}\n",
    "Y_test = indexed_test_data.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_oh = utils.to_categorical(Y_train)\n",
    "Y_test_oh = utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((2593, 2048), (2593, 1024))"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((2593, 8894), (2593, 1057))"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "indexed_train_data['user'].shape, indexed_test_data['user'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((2593, 2048, 3), (2593, 1024, 3))"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "Y_train_oh.shape, Y_test_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(input_dim, output_dim, input_length = None, name = None):\n",
    "    input_tensor = Input(shape = (input_length, ), name = name)\n",
    "    embedding_layer = layers.Embedding(input_dim = input_dim, output_dim = output_dim, input_length = input_length, mask_zero = True, name = \"embedding_{}\".format(name))(input_tensor)\n",
    "\n",
    "    return input_tensor, embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embeddings(feature_map, max_length = None):\n",
    "    input_tensors = {}\n",
    "    output_tensors = {}\n",
    "\n",
    "    input_dims = {feature: len(feature_map[feature]) for feature in feature_map}\n",
    "    \n",
    "    output_dims = {}\n",
    "    for feature in features:\n",
    "        if len(feature_map[feature]) < 10:\n",
    "            output_dims[feature] = 8\n",
    "        if 10 <= len(feature_map[feature]) < 1000:\n",
    "            output_dims[feature] = 64\n",
    "        elif len(feature_map[feature]) >= 1000:\n",
    "            output_dims[feature] = 256\n",
    "  \n",
    "    for feature in features:\n",
    "        input_tensors[feature], output_tensors[feature] = create_embeddings(input_dims[feature], output_dims[feature], max_length, feature)\n",
    "\n",
    "    return input_tensors, output_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "({'user': <tf.Tensor 'user:0' shape=(None, None) dtype=float32>,\n",
       "  'format': <tf.Tensor 'format:0' shape=(None, None) dtype=float32>,\n",
       "  'token': <tf.Tensor 'token:0' shape=(None, None) dtype=float32>,\n",
       "  'part_of_speech': <tf.Tensor 'part_of_speech:0' shape=(None, None) dtype=float32>},\n",
       " {'user': <tf.Tensor 'embedding_user/Identity:0' shape=(None, None, 256) dtype=float32>,\n",
       "  'format': <tf.Tensor 'embedding_format/Identity:0' shape=(None, None, 8) dtype=float32>,\n",
       "  'token': <tf.Tensor 'embedding_token/Identity:0' shape=(None, None, 256) dtype=float32>,\n",
       "  'part_of_speech': <tf.Tensor 'embedding_part_of_speech/Identity:0' shape=(None, None, 64) dtype=float32>})"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "input_tensors, output_tensors = build_embeddings(feature_map_train)\n",
    "input_tensors, output_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [output_tensors[feature] for feature in features]\n",
    "embeddings_tensors = layers.Concatenate(name=\"embedding_all_features\")(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_layers(X, units, dropout = 0.0, num_layers = 1):\n",
    "    for j in range(num_layers):\n",
    "        X = layers.LSTM(units = units, dropout = dropout, return_sequences = True, name = \"LSTM_layer_{}\".format(num_layers))(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lstm_layers(embeddings_tensors, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer(X, units, dropout = 0.0, activation = 'softmax'):\n",
    "    X = layers.Dropout(dropout)(X)\n",
    "    X = layers.Dense(units = units, activation = activation)(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dense_layer(X, 256, 0.2)\n",
    "outputs = dense_layer(X, 3, 0.1, 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nuser (InputLayer)               [(None, None)]       0                                            \n__________________________________________________________________________________________________\nformat (InputLayer)             [(None, None)]       0                                            \n__________________________________________________________________________________________________\ntoken (InputLayer)              [(None, None)]       0                                            \n__________________________________________________________________________________________________\npart_of_speech (InputLayer)     [(None, None)]       0                                            \n__________________________________________________________________________________________________\nembedding_user (Embedding)      (None, None, 256)    664064      user[0][0]                       \n__________________________________________________________________________________________________\nembedding_format (Embedding)    (None, None, 8)      32          format[0][0]                     \n__________________________________________________________________________________________________\nembedding_token (Embedding)     (None, None, 256)    503808      token[0][0]                      \n__________________________________________________________________________________________________\nembedding_part_of_speech (Embed (None, None, 64)     1088        part_of_speech[0][0]             \n__________________________________________________________________________________________________\nembedding_all_features (Concate (None, None, 584)    0           embedding_user[0][0]             \n                                                                 embedding_format[0][0]           \n                                                                 embedding_token[0][0]            \n                                                                 embedding_part_of_speech[0][0]   \n__________________________________________________________________________________________________\nLSTM_layer_1 (LSTM)             (None, None, 256)    861184      embedding_all_features[0][0]     \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, None, 256)    0           LSTM_layer_1[0][0]               \n__________________________________________________________________________________________________\ndense (Dense)                   (None, None, 256)    65792       dropout[0][0]                    \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, None, 256)    0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, None, 3)      771         dropout_1[0][0]                  \n==================================================================================================\nTotal params: 2,096,739\nTrainable params: 2,096,739\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = [input_tensors[feature] for feature in features]\n",
    "LSTM_model = models.Model(inputs = inputs, outputs = outputs)\n",
    "LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [indexed_train_data[feature] for feature in features]\n",
    "X_test = [indexed_test_data[feature] for feature in features]\n",
    "LSTM_model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/15\n",
      "41/41 [==============================] - 89s 2s/step - loss: 0.2913 - accuracy: 0.4097 - val_loss: 0.0891 - val_accuracy: 0.1266\n",
      "Epoch 2/15\n",
      "41/41 [==============================] - 89s 2s/step - loss: 0.2846 - accuracy: 0.4097 - val_loss: 0.0870 - val_accuracy: 0.1266\n",
      "Epoch 3/15\n",
      "41/41 [==============================] - 90s 2s/step - loss: 0.2784 - accuracy: 0.4097 - val_loss: 0.0851 - val_accuracy: 0.1266\n",
      "Epoch 4/15\n",
      "41/41 [==============================] - 88s 2s/step - loss: 0.2726 - accuracy: 0.4097 - val_loss: 0.0833 - val_accuracy: 0.1266\n",
      "Epoch 5/15\n",
      "41/41 [==============================] - 88s 2s/step - loss: 0.2674 - accuracy: 0.4097 - val_loss: 0.0817 - val_accuracy: 0.1266\n",
      "Epoch 6/15\n",
      "41/41 [==============================] - 88s 2s/step - loss: 0.2625 - accuracy: 0.4097 - val_loss: 0.0802 - val_accuracy: 0.1266\n",
      "Epoch 7/15\n",
      "41/41 [==============================] - 88s 2s/step - loss: 0.2580 - accuracy: 0.4097 - val_loss: 0.0789 - val_accuracy: 0.1266\n",
      "Epoch 8/15\n",
      "41/41 [==============================] - 88s 2s/step - loss: 0.2540 - accuracy: 0.4097 - val_loss: 0.0776 - val_accuracy: 0.1266\n",
      "Epoch 9/15\n",
      "41/41 [==============================] - 87s 2s/step - loss: 0.2502 - accuracy: 0.4097 - val_loss: 0.0764 - val_accuracy: 0.1266\n",
      "Epoch 10/15\n",
      "41/41 [==============================] - 89s 2s/step - loss: 0.2467 - accuracy: 0.4097 - val_loss: 0.0753 - val_accuracy: 0.1266\n",
      "Epoch 11/15\n",
      "41/41 [==============================] - 1883s 46s/step - loss: 0.2435 - accuracy: 0.4097 - val_loss: 0.0743 - val_accuracy: 0.1266\n",
      "Epoch 12/15\n",
      "32/41 [======================>.......] - ETA: 18s - loss: 0.2384 - accuracy: 0.4070"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b12f23c4e91b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m LSTM_model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train_oh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LSTM_model.fit(\n",
    "    x = X_train,\n",
    "    y = Y_train_oh,\n",
    "    batch_size = 64,\n",
    "    epochs = 15,\n",
    "    validation_data = (X_test, Y_test_oh) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}