{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import defaultdict, namedtuple\n",
    "from io import open\n",
    "import math\n",
    "import os\n",
    "from random import shuffle, uniform\n",
    "\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, key = None):\n",
    "    \"\"\"\n",
    "    This method loads and returns the data in filename. If the data is labelled training data, it returns labels too.\n",
    "\n",
    "    Parameters:\n",
    "        filename: the location of the training or test data you want to load.\n",
    "        key: the labels for the test data should we be loading in a test data\n",
    "\n",
    "    Returns:\n",
    "        data: a list of InstanceData objects from that data type and track, includes the labels\n",
    "    \"\"\"\n",
    "\n",
    "    # 'data' stores a list of 'InstanceData's as values.\n",
    "    data = []\n",
    "\n",
    "    # If this is training data, then 'labels' is a dict that contains instance_ids as keys and labels as values.\n",
    "    training = False\n",
    "    if filename.find('train') != -1:\n",
    "        training = True\n",
    "\n",
    "    if training:\n",
    "        labels = dict()\n",
    "\n",
    "    test_key = [] \n",
    "    if key:    \n",
    "        print('Loading test labels...')\n",
    "        with open(key, 'rt', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                temp = dict()\n",
    "                temp['instance_id'], temp['label'] = line.split()\n",
    "                temp['label'] = float(temp['label'])\n",
    "                test_key.append(temp['label'])\n",
    "\n",
    "    num_exercises = 0\n",
    "    print('Loading instances...')\n",
    "    instance_properties = dict()\n",
    "\n",
    "    with open(filename, 'rt') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            # If there's nothing in the line, then we're done with the exercise. Print if needed, otherwise continue\n",
    "            if len(line) == 0:\n",
    "                num_exercises += 1\n",
    "                if num_exercises % 100000 == 0:\n",
    "                    print('Loaded ' + str(len(data)) + ' instances across ' + str(num_exercises) + ' exercises...')\n",
    "                instance_properties = dict()\n",
    "\n",
    "            # If the line starts with #, then we're beginning a new exercise\n",
    "            elif line[0] == '#':\n",
    "                if 'prompt' in line:\n",
    "                    instance_properties['prompt'] = line.split(':')[1]\n",
    "                else:\n",
    "                    list_of_exercise_parameters = line[2:].split()\n",
    "                    for exercise_parameter in list_of_exercise_parameters:\n",
    "                        [key, value] = exercise_parameter.split(':')\n",
    "                        if key == 'countries':\n",
    "                            value = value.split('|')\n",
    "                        elif key == 'days':\n",
    "                            value = float(value)\n",
    "                        elif key == 'time':\n",
    "                            if value == 'null':\n",
    "                                value = None\n",
    "                            else:\n",
    "                                assert '.' not in value\n",
    "                                value = int(value)\n",
    "                        instance_properties[key] = value\n",
    "\n",
    "            # Otherwise we're parsing a new Instance for the current exercise\n",
    "            else:\n",
    "                line = line.split()\n",
    "                if training:\n",
    "                    assert len(line) == 7\n",
    "                else:\n",
    "                    assert len(line) == 6\n",
    "                assert len(line[0]) == 12\n",
    "\n",
    "                instance_properties['instance_id'] = line[0]\n",
    "                instance_properties['token'] = line[1]\n",
    "                instance_properties['part_of_speech'] = line[2]\n",
    "                instance_properties['dependency_label'] = line[4]\n",
    "                instance_properties['dependency_edge_head'] = int(line[5])\n",
    "                if training:\n",
    "                    label = float(line[6])\n",
    "                    labels[instance_properties['instance_id']] = label\n",
    "                    instance_properties['label'] = float(line[6])\n",
    "                if key and test_key != []:\n",
    "                    instance_properties['label'] = test_key.pop(0)\n",
    "                data.append(InstanceData(instance_properties=instance_properties))\n",
    "\n",
    "        print('Done loading ' + str(len(data)) + ' instances across ' + str(num_exercises) +\n",
    "              ' exercises.\\n')\n",
    "\n",
    "    return data\n",
    "\n",
    "class InstanceData(object):\n",
    "    \"\"\"\n",
    "    A bare-bones class to store the included properties of each instance. This is meant to act as easy access to the\n",
    "    data, and provides a launching point for deriving your own features from the data.\n",
    "    \"\"\"\n",
    "    def __init__(self, instance_properties):\n",
    "\n",
    "        # Parameters specific to this instance\n",
    "        self.instance_id = instance_properties['instance_id']\n",
    "        self.token = instance_properties['token']\n",
    "        self.part_of_speech = instance_properties['part_of_speech']\n",
    "        # self.morphological_features = instance_properties['morphological_features']\n",
    "        self.dependency_label = instance_properties['dependency_label']\n",
    "        self.dependency_edge_head = instance_properties['dependency_edge_head']\n",
    "\n",
    "        # Derived parameters specific to this instance\n",
    "        self.exercise_index = int(self.instance_id[8:10])\n",
    "        self.token_index = int(self.instance_id[10:12])\n",
    "\n",
    "        # Derived parameters specific to this exercise\n",
    "        self.exercise_id = self.instance_id[:10]\n",
    "\n",
    "        # Parameters shared across the whole session\n",
    "        self.user = instance_properties['user']\n",
    "        self.countries = instance_properties['countries']\n",
    "        self.days = instance_properties['days']\n",
    "        self.client = instance_properties['client']\n",
    "        self.session = instance_properties['session']\n",
    "        self.format = instance_properties['format']\n",
    "        self.time = instance_properties['time']\n",
    "        self.prompt = instance_properties.get('prompt', None)\n",
    "\n",
    "        # Label\n",
    "        self.label = instance_properties['label']\n",
    "\n",
    "        # Derived parameters shared across the whole session\n",
    "        self.session_id = self.instance_id[:8]\n",
    "\n",
    "    # Get the 0,1 label\n",
    "    def get_label(self):\n",
    "        return self.label\n",
    "\n",
    "    # Exercise-level features \n",
    "    def get_format(self):\n",
    "        return self.format\n",
    "    def get_user(self):\n",
    "        return self.user\n",
    "    def get_countries(self):\n",
    "        return self.countries\n",
    "    def get_session(self):\n",
    "        return self.session\n",
    "    \n",
    "    # Word-level features\n",
    "    def get_token(self):\n",
    "        return self.token.lower()\n",
    "    def get_part_of_speech(self):\n",
    "        return self.part_of_speech\n",
    "    def get_dependency_label(self):\n",
    "        return self.dependency_label\n",
    "\n",
    "    def to_features(self):\n",
    "        \"\"\"\n",
    "        Prepares those features that we wish to use in the LogisticRegression example in this file. We introduce a bias,\n",
    "        and take a few included features to use. Note that this dict restructures the corresponding features of the\n",
    "        input dictionary, 'instance_properties'.\n",
    "\n",
    "        Returns:\n",
    "            to_return: a representation of the features we'll use for logistic regression in a dict. A key/feature is a\n",
    "                key/value pair of the original 'instance_properties' dict, and we encode this feature as 1.0 for 'hot'.\n",
    "        \"\"\"\n",
    "        to_return = dict()\n",
    "\n",
    "        to_return['bias'] = 1.0\n",
    "        to_return['user:' + self.user] = 1.0\n",
    "        to_return['format:' + self.format] = 1.0\n",
    "        to_return['token:' + self.token.lower()] = 1.0\n",
    "\n",
    "        to_return['part_of_speech:' + self.part_of_speech] = 1.0\n",
    "        # for morphological_feature in self.morphological_features:\n",
    "        #     to_return['morphological_feature:' + morphological_feature] = 1.0\n",
    "        to_return['dependency_label:' + self.dependency_label] = 1.0\n",
    "\n",
    "        return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset\n",
    "def get_raw_dataset(train, test, key):\n",
    "    print(\"Getting training data...\")\n",
    "    training_data = load_data(train)\n",
    "\n",
    "    print(\"Getting test data...\")\n",
    "    test_data = load_data(test, key)\n",
    "\n",
    "    return training_data, test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Getting training data...\n",
      "Loading instances...\n",
      "Loaded 285970 instances across 100000 exercises...\n",
      "Loaded 567849 instances across 200000 exercises...\n",
      "Loaded 850501 instances across 300000 exercises...\n",
      "Done loading 926646 instances across 326792 exercises.\n",
      "\n",
      "Getting test data...\n",
      "Loading test labels...\n",
      "Loading instances...\n",
      "Done loading 135521 instances across 41753 exercises.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = get_raw_dataset(\"../data_fr_en/fr_en.slam.20190204.train\", \"../data_fr_en/fr_en.slam.20190204.test\", \"../data_fr_en/fr_en.slam.20190204.test.key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the dataset into a pandas dataframe that only contains the labels and features\n",
    "# we want to use in our model\n",
    "def build_formatted_dataset(data):\n",
    "    users, formats, countries, sessions, tokens, part_of_speeches, dependency_labels, labels = [], [], [] ,[], [], [], [], []\n",
    "    \n",
    "    for instance_data in data:\n",
    "        users.append(instance_data.get_user())\n",
    "        formats.append(instance_data.get_format())\n",
    "        countries.append(instance_data.get_countries())\n",
    "        sessions.append(instance_data.get_session())\n",
    "        tokens.append(instance_data.get_token())\n",
    "        part_of_speeches.append(instance_data.get_part_of_speech())\n",
    "        dependency_labels.append(instance_data.get_dependency_label())\n",
    "        labels.append(instance_data.get_label())\n",
    "\n",
    "    dataset = {'user':users, 'country':countries, 'format':formats, 'session':sessions, 'token':tokens, 'part_of_speech':part_of_speeches, 'dependency_label':dependency_labels, 'label':labels}\n",
    "    dataset = pd.DataFrame.from_dict(dataset)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_train_data = build_formatted_dataset(train_data)\n",
    "formatted_test_data = build_formatted_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            user country             format   session   token part_of_speech  \\\n",
       "0       YjS/mQOx    [CA]  reverse_translate    lesson      le            DET   \n",
       "1       YjS/mQOx    [CA]  reverse_translate    lesson  garçon           NOUN   \n",
       "2       YjS/mQOx    [CA]  reverse_translate    lesson      je           PRON   \n",
       "3       YjS/mQOx    [CA]  reverse_translate    lesson    suis           VERB   \n",
       "4       YjS/mQOx    [CA]  reverse_translate    lesson     une            DET   \n",
       "...          ...     ...                ...       ...     ...            ...   \n",
       "926641  GIYQ1bA5    [GB]        reverse_tap    lesson   femme           NOUN   \n",
       "926642  GIYQ1bA5    [GB]        reverse_tap  practice      je           PRON   \n",
       "926643  GIYQ1bA5    [GB]        reverse_tap  practice   mange           VERB   \n",
       "926644  GIYQ1bA5    [GB]        reverse_tap  practice      l'            DET   \n",
       "926645  GIYQ1bA5    [GB]        reverse_tap  practice   homme           NOUN   \n",
       "\n",
       "       dependency_label  label  \n",
       "0                   det    0.0  \n",
       "1                  ROOT    0.0  \n",
       "2                 nsubj    0.0  \n",
       "3                   cop    0.0  \n",
       "4                   det    0.0  \n",
       "...                 ...    ...  \n",
       "926641             dobj    0.0  \n",
       "926642            nsubj    0.0  \n",
       "926643             ROOT    0.0  \n",
       "926644              det    0.0  \n",
       "926645             ROOT    0.0  \n",
       "\n",
       "[926646 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>country</th>\n      <th>format</th>\n      <th>session</th>\n      <th>token</th>\n      <th>part_of_speech</th>\n      <th>dependency_label</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>YjS/mQOx</td>\n      <td>[CA]</td>\n      <td>reverse_translate</td>\n      <td>lesson</td>\n      <td>le</td>\n      <td>DET</td>\n      <td>det</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>YjS/mQOx</td>\n      <td>[CA]</td>\n      <td>reverse_translate</td>\n      <td>lesson</td>\n      <td>garçon</td>\n      <td>NOUN</td>\n      <td>ROOT</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>YjS/mQOx</td>\n      <td>[CA]</td>\n      <td>reverse_translate</td>\n      <td>lesson</td>\n      <td>je</td>\n      <td>PRON</td>\n      <td>nsubj</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>YjS/mQOx</td>\n      <td>[CA]</td>\n      <td>reverse_translate</td>\n      <td>lesson</td>\n      <td>suis</td>\n      <td>VERB</td>\n      <td>cop</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>YjS/mQOx</td>\n      <td>[CA]</td>\n      <td>reverse_translate</td>\n      <td>lesson</td>\n      <td>une</td>\n      <td>DET</td>\n      <td>det</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>926641</th>\n      <td>GIYQ1bA5</td>\n      <td>[GB]</td>\n      <td>reverse_tap</td>\n      <td>lesson</td>\n      <td>femme</td>\n      <td>NOUN</td>\n      <td>dobj</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>926642</th>\n      <td>GIYQ1bA5</td>\n      <td>[GB]</td>\n      <td>reverse_tap</td>\n      <td>practice</td>\n      <td>je</td>\n      <td>PRON</td>\n      <td>nsubj</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>926643</th>\n      <td>GIYQ1bA5</td>\n      <td>[GB]</td>\n      <td>reverse_tap</td>\n      <td>practice</td>\n      <td>mange</td>\n      <td>VERB</td>\n      <td>ROOT</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>926644</th>\n      <td>GIYQ1bA5</td>\n      <td>[GB]</td>\n      <td>reverse_tap</td>\n      <td>practice</td>\n      <td>l'</td>\n      <td>DET</td>\n      <td>det</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>926645</th>\n      <td>GIYQ1bA5</td>\n      <td>[GB]</td>\n      <td>reverse_tap</td>\n      <td>practice</td>\n      <td>homme</td>\n      <td>NOUN</td>\n      <td>ROOT</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>926646 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "formatted_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            user country             format   session   token part_of_speech  \\\n",
       "0       YjS/mQOx    [CA]             listen    lesson      j'           PRON   \n",
       "1       YjS/mQOx    [CA]             listen    lesson   adore           VERB   \n",
       "2       YjS/mQOx    [CA]             listen    lesson  gagner           VERB   \n",
       "3       YjS/mQOx    [CA]  reverse_translate    lesson    nous           PRON   \n",
       "4       YjS/mQOx    [CA]  reverse_translate    lesson  allons            AUX   \n",
       "...          ...     ...                ...       ...     ...            ...   \n",
       "135516  GIYQ1bA5    [GB]  reverse_translate  practice      un            DET   \n",
       "135517  GIYQ1bA5    [GB]  reverse_translate  practice  enfant           NOUN   \n",
       "135518  GIYQ1bA5    [GB]        reverse_tap  practice     oui           INTJ   \n",
       "135519  GIYQ1bA5    [GB]        reverse_tap  practice      je           PRON   \n",
       "135520  GIYQ1bA5    [GB]        reverse_tap  practice    peux           VERB   \n",
       "\n",
       "       dependency_label  label  \n",
       "0                 nsubj    0.0  \n",
       "1                  ROOT    0.0  \n",
       "2                 xcomp    0.0  \n",
       "3                 nsubj    0.0  \n",
       "4                   aux    1.0  \n",
       "...                 ...    ...  \n",
       "135516              det    0.0  \n",
       "135517             dobj    0.0  \n",
       "135518        discourse    0.0  \n",
       "135519            nsubj    0.0  \n",
       "135520             ROOT    0.0  \n",
       "\n",
       "[135521 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>country</th>\n      <th>format</th>\n      <th>session</th>\n      <th>token</th>\n      <th>part_of_speech</th>\n      <th>dependency_label</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>YjS/mQOx</td>\n      <td>[CA]</td>\n      <td>listen</td>\n      <td>lesson</td>\n      <td>j'</td>\n      <td>PRON</td>\n      <td>nsubj</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>YjS/mQOx</td>\n      <td>[CA]</td>\n      <td>listen</td>\n      <td>lesson</td>\n      <td>adore</td>\n      <td>VERB</td>\n      <td>ROOT</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>YjS/mQOx</td>\n      <td>[CA]</td>\n      <td>listen</td>\n      <td>lesson</td>\n      <td>gagner</td>\n      <td>VERB</td>\n      <td>xcomp</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>YjS/mQOx</td>\n      <td>[CA]</td>\n      <td>reverse_translate</td>\n      <td>lesson</td>\n      <td>nous</td>\n      <td>PRON</td>\n      <td>nsubj</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>YjS/mQOx</td>\n      <td>[CA]</td>\n      <td>reverse_translate</td>\n      <td>lesson</td>\n      <td>allons</td>\n      <td>AUX</td>\n      <td>aux</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>135516</th>\n      <td>GIYQ1bA5</td>\n      <td>[GB]</td>\n      <td>reverse_translate</td>\n      <td>practice</td>\n      <td>un</td>\n      <td>DET</td>\n      <td>det</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>135517</th>\n      <td>GIYQ1bA5</td>\n      <td>[GB]</td>\n      <td>reverse_translate</td>\n      <td>practice</td>\n      <td>enfant</td>\n      <td>NOUN</td>\n      <td>dobj</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>135518</th>\n      <td>GIYQ1bA5</td>\n      <td>[GB]</td>\n      <td>reverse_tap</td>\n      <td>practice</td>\n      <td>oui</td>\n      <td>INTJ</td>\n      <td>discourse</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>135519</th>\n      <td>GIYQ1bA5</td>\n      <td>[GB]</td>\n      <td>reverse_tap</td>\n      <td>practice</td>\n      <td>je</td>\n      <td>PRON</td>\n      <td>nsubj</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>135520</th>\n      <td>GIYQ1bA5</td>\n      <td>[GB]</td>\n      <td>reverse_tap</td>\n      <td>practice</td>\n      <td>peux</td>\n      <td>VERB</td>\n      <td>ROOT</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>135521 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "formatted_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_train_data.to_pickle(\"../data_fr_en/fr_en_train_data.pkl\")\n",
    "formatted_test_data.to_pickle(\"../data_fr_en/fr_en_test_data.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}