{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import defaultdict, namedtuple\n",
    "from io import open\n",
    "import math\n",
    "import os\n",
    "from random import shuffle, uniform\n",
    "\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, key = None):\n",
    "    \"\"\"\n",
    "    This method loads and returns the data in filename. If the data is labelled training data, it returns labels too.\n",
    "\n",
    "    Parameters:\n",
    "        filename: the location of the training or test data you want to load.\n",
    "        key: the labels for the test data should we be loading in a test data\n",
    "\n",
    "    Returns:\n",
    "        data: a list of InstanceData objects from that data type and track, includes the labels\n",
    "    \"\"\"\n",
    "\n",
    "    # 'data' stores a list of 'InstanceData's as values.\n",
    "    data = []\n",
    "\n",
    "    # If this is training data, then 'labels' is a dict that contains instance_ids as keys and labels as values.\n",
    "    training = False\n",
    "    if filename.find('train') != -1:\n",
    "        training = True\n",
    "\n",
    "    if training:\n",
    "        labels = dict()\n",
    "\n",
    "    test_key = [] \n",
    "    if key:    \n",
    "        print('Loading test labels...')\n",
    "        with open(key, 'rt', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                temp = dict()\n",
    "                temp['instance_id'], temp['label'] = line.split()\n",
    "                temp['label'] = float(temp['label'])\n",
    "                test_key.append(temp['label'])\n",
    "\n",
    "    num_exercises = 0\n",
    "    print('Loading instances...')\n",
    "    instance_properties = dict()\n",
    "\n",
    "    with open(filename, 'rt') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            # If there's nothing in the line, then we're done with the exercise. Print if needed, otherwise continue\n",
    "            if len(line) == 0:\n",
    "                num_exercises += 1\n",
    "                if num_exercises % 100000 == 0:\n",
    "                    print('Loaded ' + str(len(data)) + ' instances across ' + str(num_exercises) + ' exercises...')\n",
    "                instance_properties = dict()\n",
    "\n",
    "            # If the line starts with #, then we're beginning a new exercise\n",
    "            elif line[0] == '#':\n",
    "                if 'prompt' in line:\n",
    "                    instance_properties['prompt'] = line.split(':')[1]\n",
    "                else:\n",
    "                    list_of_exercise_parameters = line[2:].split()\n",
    "                    for exercise_parameter in list_of_exercise_parameters:\n",
    "                        [key, value] = exercise_parameter.split(':')\n",
    "                        if key == 'countries':\n",
    "                            value = value.split('|')\n",
    "                        elif key == 'days':\n",
    "                            value = float(value)\n",
    "                        elif key == 'time':\n",
    "                            if value == 'null':\n",
    "                                value = None\n",
    "                            else:\n",
    "                                assert '.' not in value\n",
    "                                value = int(value)\n",
    "                        instance_properties[key] = value\n",
    "\n",
    "            # Otherwise we're parsing a new Instance for the current exercise\n",
    "            else:\n",
    "                line = line.split()\n",
    "                if training:\n",
    "                    assert len(line) == 7\n",
    "                else:\n",
    "                    assert len(line) == 6\n",
    "                assert len(line[0]) == 12\n",
    "\n",
    "                instance_properties['instance_id'] = line[0]\n",
    "                instance_properties['token'] = line[1]\n",
    "                instance_properties['part_of_speech'] = line[2]\n",
    "\n",
    "                # instance_properties['morphological_features'] = dict()\n",
    "                # for l in line[3].split('|'):\n",
    "                #     [key, value] = l.split('=')\n",
    "                #     if key == 'Person':\n",
    "                #         value = int(value)\n",
    "                #     instance_properties['morphological_features'][key] = value\n",
    "\n",
    "                instance_properties['dependency_label'] = line[4]\n",
    "                instance_properties['dependency_edge_head'] = int(line[5])\n",
    "                if training:\n",
    "                    label = float(line[6])\n",
    "                    labels[instance_properties['instance_id']] = label\n",
    "                    instance_properties['label'] = float(line[6])\n",
    "                if key and test_key != []:\n",
    "                    instance_properties['label'] = test_key.pop(0)\n",
    "                data.append(InstanceData(instance_properties=instance_properties))\n",
    "\n",
    "        print('Done loading ' + str(len(data)) + ' instances across ' + str(num_exercises) +\n",
    "              ' exercises.\\n')\n",
    "\n",
    "    # if training: return data, labels\n",
    "\n",
    "    return data\n",
    "\n",
    "class InstanceData(object):\n",
    "    \"\"\"\n",
    "    A bare-bones class to store the included properties of each instance. This is meant to act as easy access to the\n",
    "    data, and provides a launching point for deriving your own features from the data.\n",
    "    \"\"\"\n",
    "    def __init__(self, instance_properties):\n",
    "\n",
    "        # Parameters specific to this instance\n",
    "        self.instance_id = instance_properties['instance_id']\n",
    "        self.token = instance_properties['token']\n",
    "        self.part_of_speech = instance_properties['part_of_speech']\n",
    "        # self.morphological_features = instance_properties['morphological_features']\n",
    "        self.dependency_label = instance_properties['dependency_label']\n",
    "        self.dependency_edge_head = instance_properties['dependency_edge_head']\n",
    "\n",
    "        # Derived parameters specific to this instance\n",
    "        self.exercise_index = int(self.instance_id[8:10])\n",
    "        self.token_index = int(self.instance_id[10:12])\n",
    "\n",
    "        # Derived parameters specific to this exercise\n",
    "        self.exercise_id = self.instance_id[:10]\n",
    "\n",
    "        # Parameters shared across the whole session\n",
    "        self.user = instance_properties['user']\n",
    "        self.countries = instance_properties['countries']\n",
    "        self.days = instance_properties['days']\n",
    "        self.client = instance_properties['client']\n",
    "        self.session = instance_properties['session']\n",
    "        self.format = instance_properties['format']\n",
    "        self.time = instance_properties['time']\n",
    "        self.prompt = instance_properties.get('prompt', None)\n",
    "\n",
    "        # Label\n",
    "        self.label = instance_properties['label']\n",
    "\n",
    "        # Derived parameters shared across the whole session\n",
    "        self.session_id = self.instance_id[:8]\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.label \n",
    "    def get_exercise_id(self):\n",
    "        return self.exercise_id\n",
    "    def get_format(self):\n",
    "        return self.format\n",
    "    def get_user(self):\n",
    "        return self.user\n",
    "    def get_token(self):\n",
    "        return self.token.lower()\n",
    "    def get_part_of_speech(self):\n",
    "        return self.part_of_speech\n",
    "\n",
    "    def to_features(self):\n",
    "        \"\"\"\n",
    "        Prepares those features that we wish to use in the LogisticRegression example in this file. We introduce a bias,\n",
    "        and take a few included features to use. Note that this dict restructures the corresponding features of the\n",
    "        input dictionary, 'instance_properties'.\n",
    "\n",
    "        Returns:\n",
    "            to_return: a representation of the features we'll use for logistic regression in a dict. A key/feature is a\n",
    "                key/value pair of the original 'instance_properties' dict, and we encode this feature as 1.0 for 'hot'.\n",
    "        \"\"\"\n",
    "        to_return = dict()\n",
    "\n",
    "        to_return['bias'] = 1.0\n",
    "        to_return['user:' + self.user] = 1.0\n",
    "        to_return['format:' + self.format] = 1.0\n",
    "        to_return['token:' + self.token.lower()] = 1.0\n",
    "\n",
    "        to_return['part_of_speech:' + self.part_of_speech] = 1.0\n",
    "        # for morphological_feature in self.morphological_features:\n",
    "        #     to_return['morphological_feature:' + morphological_feature] = 1.0\n",
    "        to_return['dependency_label:' + self.dependency_label] = 1.0\n",
    "\n",
    "        return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset\n",
    "def get_raw_dataset(train, test, key):\n",
    "    print(\"Getting training data...\")\n",
    "    training_data = load_data(train)\n",
    "\n",
    "    print(\"Getting test data...\")\n",
    "    test_data = load_data(test, key)\n",
    "\n",
    "    return training_data, test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Getting training data...\n",
      "Loading instances...\n",
      "Loaded 317049 instances across 100000 exercises...\n",
      "Loaded 635368 instances across 200000 exercises...\n",
      "Loaded 951536 instances across 300000 exercises...\n",
      "Loaded 1271940 instances across 400000 exercises...\n",
      "Loaded 1591344 instances across 500000 exercises...\n",
      "Loaded 1911212 instances across 600000 exercises...\n",
      "Loaded 2227444 instances across 700000 exercises...\n",
      "Loaded 2546704 instances across 800000 exercises...\n",
      "Done loading 2622957 instances across 824012 exercises.\n",
      "\n",
      "Getting test data...\n",
      "Loading test labels...\n",
      "Loading instances...\n",
      "Loaded 337728 instances across 100000 exercises...\n",
      "Done loading 386604 instances across 114586 exercises.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = get_raw_dataset(\"../data_en_es/en_es.slam.20190204.train\", \"../data_en_es/en_es.slam.20190204.test\", \"../data_en_es/en_es.slam.20190204.test.key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the dataset into a pandas dataframe that only contains the labels and features\n",
    "# we want to use in our model\n",
    "def build_formatted_dataset(data):\n",
    "    users, formats, tokens, part_of_speeches, labels = [], [], [] ,[], []\n",
    "    \n",
    "    for instance_data in data:\n",
    "        users.append(instance_data.get_user())\n",
    "        formats.append(instance_data.get_format())\n",
    "        tokens.append(instance_data.get_token())\n",
    "        part_of_speeches.append(instance_data.get_part_of_speech())\n",
    "        labels.append(instance_data.get_labels())\n",
    "\n",
    "    dataset = {'user':users, 'format':formats, 'token':tokens, 'part_of_speech':part_of_speeches, 'label':labels}\n",
    "    dataset = pd.DataFrame.from_dict(dataset)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_train_data = build_formatted_dataset(train_data)\n",
    "formatted_test_data = build_formatted_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             user             format   token part_of_speech  label\n",
       "0        XEinXf5+  reverse_translate       i           PRON    0.0\n",
       "1        XEinXf5+  reverse_translate      am           VERB    0.0\n",
       "2        XEinXf5+  reverse_translate       a            DET    0.0\n",
       "3        XEinXf5+  reverse_translate     boy           NOUN    0.0\n",
       "4        XEinXf5+  reverse_translate       i           PRON    0.0\n",
       "...           ...                ...     ...            ...    ...\n",
       "2622952  Ja1WEMqy  reverse_translate   table           NOUN    0.0\n",
       "2622953  Ja1WEMqy  reverse_translate     red           VERB    0.0\n",
       "2622954  Ja1WEMqy  reverse_translate      as            ADP    0.0\n",
       "2622955  Ja1WEMqy  reverse_translate       a            DET    1.0\n",
       "2622956  Ja1WEMqy  reverse_translate  tomato           NOUN    0.0\n",
       "\n",
       "[2622957 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>format</th>\n      <th>token</th>\n      <th>part_of_speech</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>XEinXf5+</td>\n      <td>reverse_translate</td>\n      <td>i</td>\n      <td>PRON</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>XEinXf5+</td>\n      <td>reverse_translate</td>\n      <td>am</td>\n      <td>VERB</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>XEinXf5+</td>\n      <td>reverse_translate</td>\n      <td>a</td>\n      <td>DET</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>XEinXf5+</td>\n      <td>reverse_translate</td>\n      <td>boy</td>\n      <td>NOUN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>XEinXf5+</td>\n      <td>reverse_translate</td>\n      <td>i</td>\n      <td>PRON</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2622952</th>\n      <td>Ja1WEMqy</td>\n      <td>reverse_translate</td>\n      <td>table</td>\n      <td>NOUN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2622953</th>\n      <td>Ja1WEMqy</td>\n      <td>reverse_translate</td>\n      <td>red</td>\n      <td>VERB</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2622954</th>\n      <td>Ja1WEMqy</td>\n      <td>reverse_translate</td>\n      <td>as</td>\n      <td>ADP</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2622955</th>\n      <td>Ja1WEMqy</td>\n      <td>reverse_translate</td>\n      <td>a</td>\n      <td>DET</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2622956</th>\n      <td>Ja1WEMqy</td>\n      <td>reverse_translate</td>\n      <td>tomato</td>\n      <td>NOUN</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2622957 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "formatted_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            user             format       token part_of_speech  label\n",
       "0       XEinXf5+             listen           i           PRON    0.0\n",
       "1       XEinXf5+             listen        feel           VERB    0.0\n",
       "2       XEinXf5+             listen        fine            ADJ    1.0\n",
       "3       XEinXf5+             listen         now            ADV    0.0\n",
       "4       XEinXf5+             listen           i           PRON    0.0\n",
       "...          ...                ...         ...            ...    ...\n",
       "386599  Ja1WEMqy  reverse_translate      answer           NOUN    0.0\n",
       "386600  Ja1WEMqy  reverse_translate         the            DET    0.0\n",
       "386601  Ja1WEMqy  reverse_translate      answer           NOUN    0.0\n",
       "386602  Ja1WEMqy  reverse_translate          is           VERB    0.0\n",
       "386603  Ja1WEMqy  reverse_translate  historical            ADJ    0.0\n",
       "\n",
       "[386604 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>format</th>\n      <th>token</th>\n      <th>part_of_speech</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>XEinXf5+</td>\n      <td>listen</td>\n      <td>i</td>\n      <td>PRON</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>XEinXf5+</td>\n      <td>listen</td>\n      <td>feel</td>\n      <td>VERB</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>XEinXf5+</td>\n      <td>listen</td>\n      <td>fine</td>\n      <td>ADJ</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>XEinXf5+</td>\n      <td>listen</td>\n      <td>now</td>\n      <td>ADV</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>XEinXf5+</td>\n      <td>listen</td>\n      <td>i</td>\n      <td>PRON</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>386599</th>\n      <td>Ja1WEMqy</td>\n      <td>reverse_translate</td>\n      <td>answer</td>\n      <td>NOUN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>386600</th>\n      <td>Ja1WEMqy</td>\n      <td>reverse_translate</td>\n      <td>the</td>\n      <td>DET</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>386601</th>\n      <td>Ja1WEMqy</td>\n      <td>reverse_translate</td>\n      <td>answer</td>\n      <td>NOUN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>386602</th>\n      <td>Ja1WEMqy</td>\n      <td>reverse_translate</td>\n      <td>is</td>\n      <td>VERB</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>386603</th>\n      <td>Ja1WEMqy</td>\n      <td>reverse_translate</td>\n      <td>historical</td>\n      <td>ADJ</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>386604 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "formatted_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_train_data.to_pickle(\"../data_en_es/en_es_train_data.pkl\")\n",
    "formatted_test_data.to_pickle(\"../data_en_es/en_es_test_data.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}